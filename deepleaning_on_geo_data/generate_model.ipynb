{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2555119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a78bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "XLINES = np.arange(4068,4718,10)\n",
    "\n",
    "\n",
    "def load_label(xlineidx):\n",
    "    label = np.load('MODEL/LABEL/label_XL_%s.npy' % int(XLINES[xlineidx]))\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "def plot_overlay(image, label):\n",
    "    (tmax, xmax) = np.shape(image)\n",
    "\n",
    "    label_rgb = np.zeros((tmax, xmax, 4), 'uint8')\n",
    "    label_rgb[:, :, 0] = 255\n",
    "    label_rgb[:, :, 1] = 255 - 255 * label\n",
    "    label_rgb[:, :, 2] = 255 - 255 * label\n",
    "    label_rgb[:, :, 3] = 255 * label\n",
    "\n",
    "    img = Image.fromarray(label_rgb, mode='RGBA')\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "\n",
    "def patchify(data, label, size, number, threshold):\n",
    "    (t_max, x_max) = label.shape\n",
    "    X = np.zeros((number, size, size, 1))\n",
    "    Y = np.zeros((number, size, size, 1))\n",
    "\n",
    "    n = 0\n",
    "    while n < number:\n",
    "        x = random.randint(size // 2, x_max - size // 2)\n",
    "        t = random.randint(size // 2, t_max - size // 2)\n",
    "        if np.count_nonzero(label[t - size // 2:t + size // 2, x - size // 2:x + size // 2]) > threshold:\n",
    "            X[n, :, :, 0] = data[t - size // 2:t + size // 2, x - size // 2:x + size // 2]\n",
    "            Y[n, :, :, 0] = label[t - size // 2:t + size // 2, x - size // 2:x + size // 2]\n",
    "            n = n + 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3679c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "xlineidxs = np.arange(0,len(XLINES)+1,10)\n",
    "\n",
    "size = 64\n",
    "threshold = 0\n",
    "num_train = 2000*len(xlineidxs)\n",
    "num_val = 2000\n",
    "\n",
    "# Validation data from inline 300\n",
    "X_val = np.zeros((num_val, size, size, 1))\n",
    "Y_val = np.zeros((num_val, size, size, 1))\n",
    "\n",
    "xlineidx = 2\n",
    "label = load_label(xlineidx)\n",
    "seismic = np.load('./MODEL/TRAIN/trainer_XL_%s.npy' % int(XLINES[xlineidx]))\n",
    "\n",
    "X_val, Y_val = patchify(seismic, label, size, num_val, threshold)\n",
    "\n",
    "# Training data from inlines 100, 200, 400, 500\n",
    "X_train = np.zeros((num_train, size, size, 1))\n",
    "Y_train = np.zeros((num_train, size, size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35a1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for xlineidx in xlineidxs:\n",
    "\n",
    "    label = np.load('./MODEL/LABEL/label_XL_%s.npy' % int(XLINES[xlineidx]))\n",
    "    seismic = np.load('./MODEL/TRAIN/trainer_XL_%s.npy' % int(XLINES[xlineidx]))\n",
    "\n",
    "    X_train[n:n + num_train // len(xlineidxs), ...], Y_train[n:n + num_train // len(xlineidxs), ...] = patchify(seismic, label, size,\n",
    "                                                                                        num_train // len(xlineidxs), threshold)\n",
    "    n += num_train // len(xlineidxs)\n",
    "\n",
    "\n",
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = tf.keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = tf.keras.layers.Concatenate()([us, skip])\n",
    "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "\n",
    "def UNet():\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "    inputs = tf.keras.layers.Input((size, size, 1))\n",
    "\n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f[0])  # 128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1])  # 64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2])  # 32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3])  # 16->8\n",
    "\n",
    "    bn = bottleneck(p4, f[4])\n",
    "\n",
    "    u1 = up_block(bn, c4, f[3])  # 8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2])  # 16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1])  # 32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0])  # 64 -> 128\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = UNet()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    epochs=50, verbose=1)\n",
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./MODEL/Fault_Detection_ModelV2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./MODEL/Fault_Detection_WeightV2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ccf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
